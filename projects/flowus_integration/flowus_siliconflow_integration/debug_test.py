#!/usr/bin/env python3
"""
è°ƒè¯•æµ‹è¯•è„šæœ¬ - éªŒè¯é—®é¢˜è¯Šæ–­å’Œä¿®å¤
"""
import logging
import os
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config.config_loader import ConfigLoader
from fetch_diary_data import DiaryDataFetcher
from database.mysql_client import MySQLClient
from process_diary_with_ai import DiaryAIProcessor

# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug_test.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def test_database_reference_detection():
    """æµ‹è¯•æ•°æ®åº“å¼•ç”¨æ£€æµ‹åŠŸèƒ½"""
    logger.info("=== æµ‹è¯•1: æ•°æ®åº“å¼•ç”¨æ£€æµ‹ ===")
    
    try:
        config_loader = ConfigLoader()
        fetcher = DiaryDataFetcher(config_loader)
        
        # è·å–ä¸»é¡µé¢å—å†…å®¹
        page_url = config_loader.config['flowus']['url']
        page_id = page_url.split('/')[-1].split('?')[0]
        logger.info(f"æµ‹è¯•ä¸»é¡µé¢: {page_id}")
        
        blocks_data = fetcher.flowus_client.get_page_content(page_id)
        if not blocks_data:
            logger.error("æ— æ³•è·å–ä¸»é¡µé¢å—å†…å®¹")
            return False
        
        # æµ‹è¯•æ”¹è¿›çš„æ•°æ®åº“å¼•ç”¨æ£€æµ‹
        diary_db_id = fetcher.extract_database_reference_from_blocks(blocks_data)
        
        if diary_db_id:
            logger.info(f"âœ… æˆåŠŸæ‰¾åˆ°æ—¥è®°æ•°æ®åº“: {diary_db_id}")
            return True
        else:
            logger.error("âŒ ä»ç„¶æœªæ‰¾åˆ°æ—¥è®°æ•°æ®åº“å¼•ç”¨")
            return False
            
    except Exception as e:
        logger.error(f"æµ‹è¯•æ•°æ®åº“å¼•ç”¨æ£€æµ‹å¤±è´¥: {e}")
        return False


def test_block_content_storage():
    """æµ‹è¯•å—å†…å®¹å­˜å‚¨åŠŸèƒ½"""
    logger.info("=== æµ‹è¯•2: å—å†…å®¹å­˜å‚¨ ===")
    
    try:
        config_loader = ConfigLoader()
        mysql_client = MySQLClient(config_loader.config)
        
        # è¿æ¥æ•°æ®åº“
        if not mysql_client.connect():
            logger.error("æ•°æ®åº“è¿æ¥å¤±è´¥")
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰çš„é—®é¢˜/é¡¹ç›®è®°å½•
        problem_records = mysql_client.get_recent_problem_records(days=7)
        project_records = mysql_client.get_recent_project_records(days=7)
        
        logger.info(f"æ‰¾åˆ° {len(problem_records)} ä¸ªé—®é¢˜è®°å½•, {len(project_records)} ä¸ªé¡¹ç›®è®°å½•")
        
        # æ£€æŸ¥è®°å½•æ˜¯å¦æœ‰å†…å®¹
        records_with_content = 0
        for record in problem_records + project_records:
            content = record.get('content', '')
            if content and len(content.strip()) > 0:
                records_with_content += 1
        
        logger.info(f"æœ‰å†…å®¹çš„è®°å½•æ•°: {records_with_content}")
        
        if records_with_content > 0:
            logger.info("âœ… å—å†…å®¹å­˜å‚¨åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
            success = True
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰å†…å®¹çš„è®°å½•ï¼Œå¯èƒ½éœ€è¦é‡æ–°è·å–æ•°æ®")
            success = False
        
        mysql_client.disconnect()
        return success
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å—å†…å®¹å­˜å‚¨å¤±è´¥: {e}")
        return False


def test_local_backup():
    """æµ‹è¯•æœ¬åœ°å¤‡ä»½åŠŸèƒ½"""
    logger.info("=== æµ‹è¯•3: æœ¬åœ°å¤‡ä»½åŠŸèƒ½ ===")
    
    try:
        config_loader = ConfigLoader()
        processor = DiaryAIProcessor(config_loader)
        
        # æµ‹è¯•æœ¬åœ°å¤‡ä»½ä¿å­˜
        test_content = f"""# æµ‹è¯•å†…å®¹

è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å†…å®¹ï¼Œç”¨äºéªŒè¯æœ¬åœ°å¤‡ä»½åŠŸèƒ½ã€‚

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æµ‹è¯•ç»“æœ

å¦‚æœçœ‹åˆ°è¿™ä¸ªæ–‡ä»¶ï¼Œè¯´æ˜æœ¬åœ°å¤‡ä»½åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚
"""
        
        test_response_json = {
            'model': 'test-model',
            'id': 'test-response-id'
        }
        
        # è°ƒç”¨æœ¬åœ°å¤‡ä»½æ–¹æ³•
        backup_success = processor.save_to_local_backup(test_content, test_response_json)
        
        if backup_success:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
            output_dir = config_loader.config['output']['output_dir']
            local_file_path = os.path.join(output_dir, config_loader.config['output']['filename'])
            
            if os.path.exists(local_file_path):
                with open(local_file_path, 'r', encoding='utf-8') as f:
                    saved_content = f.read()
                
                if test_content in saved_content:
                    logger.info("âœ… æœ¬åœ°å¤‡ä»½åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
                    logger.info(f"å¤‡ä»½æ–‡ä»¶ä½ç½®: {local_file_path}")
                    return True
                else:
                    logger.error("âŒ å¤‡ä»½æ–‡ä»¶å†…å®¹ä¸æ­£ç¡®")
                    return False
            else:
                logger.error(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {local_file_path}")
                return False
        else:
            logger.error("âŒ æœ¬åœ°å¤‡ä»½ä¿å­˜å¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"æµ‹è¯•æœ¬åœ°å¤‡ä»½å¤±è´¥: {e}")
        return False


def test_config_parameters():
    """æµ‹è¯•é…ç½®å‚æ•°ä½¿ç”¨"""
    logger.info("=== æµ‹è¯•4: é…ç½®å‚æ•°ä½¿ç”¨ ===")
    
    try:
        config_loader = ConfigLoader()
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®åº“å‚æ•°
        db_config = config_loader.config.get('database', {})
        page_size = db_config.get('page_size', 100)
        recent_days = db_config.get('recent_days', 30)
        include_properties = db_config.get('include_properties', True)
        
        logger.info(f"é…ç½®å‚æ•°: page_size={page_size}, recent_days={recent_days}, include_properties={include_properties}")
        
        # æµ‹è¯•FlowUså®¢æˆ·ç«¯æ˜¯å¦ä½¿ç”¨è¿™äº›å‚æ•°
        from clients.flowus_client import FlowUsClient
        flowus_client = FlowUsClient(config_loader)
        
        # è¿™é‡Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥è°ƒç”¨get_database_contentï¼Œå› ä¸ºæ²¡æœ‰çœŸå®çš„æ•°æ®åº“ID
        # ä½†æˆ‘ä»¬å¯ä»¥æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½
        if page_size != 100 or recent_days != 30:
            logger.info("âœ… é…ç½®å‚æ•°å·²æ­£ç¡®åŠ è½½ä¸”ä¸æ˜¯é»˜è®¤å€¼")
            return True
        else:
            logger.info("âš ï¸ ä½¿ç”¨çš„æ˜¯é»˜è®¤é…ç½®å€¼ï¼Œä½†è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„")
            return True
            
    except Exception as e:
        logger.error(f"æµ‹è¯•é…ç½®å‚æ•°å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹è°ƒè¯•æµ‹è¯•...")
    logger.info("=" * 60)
    
    test_results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results.append(("æ•°æ®åº“å¼•ç”¨æ£€æµ‹", test_database_reference_detection()))
    test_results.append(("å—å†…å®¹å­˜å‚¨", test_block_content_storage()))
    test_results.append(("æœ¬åœ°å¤‡ä»½åŠŸèƒ½", test_local_backup()))
    test_results.append(("é…ç½®å‚æ•°ä½¿ç”¨", test_config_parameters()))
    
    # æ±‡æ€»ç»“æœ
    logger.info("=" * 60)
    logger.info("=== æµ‹è¯•ç»“æœæ±‡æ€» ===")
    
    passed_tests = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")
        if result:
            passed_tests += 1
    
    logger.info(f"æ€»è®¡: {passed_tests}/{total_tests} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed_tests == total_tests:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é—®é¢˜ä¿®å¤æˆåŠŸã€‚")
        return True
    elif passed_tests > 0:
        logger.warning("âš ï¸ éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œè¿˜æœ‰ä¸€äº›é—®é¢˜éœ€è¦è§£å†³ã€‚")
        return False
    else:
        logger.error("ğŸ’¥ æ‰€æœ‰æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è¯Šæ–­ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)